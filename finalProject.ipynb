{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Entrenamiento y optimización de Modelos de Machine Learning </h1>\n",
    "<h3> Proyecto final: </h3> \n",
    "<h4> Sergio Andres Rios Gomez </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Definición de objetivo </h2>\n",
    "<p> Hacer uso eficiente de la información transaccional con el fin de optimizar los procesos internos al interior de la entidad  </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Contexto comercial</h2>\n",
    "<p> Los sistemas de pago de bajo valor SPBV, son mecanismos de funcionamiento de la economía moderna, donde participa un originador (Pagador) y un beneficiario (receptor) de los recursos. Ante el alto volumen de pagos y la necesidad de automatizar estas transacciones nacen compañias especializadas en realizar toda esta intermediación. </p>\n",
    "\n",
    "<p> La empresa SPBV se encarga de prestar los servicios tecnologicos y transaccionales a las Cooperativas de la red. </p>\n",
    "\n",
    "<p> La data que será procesada en la presente entrega, corresponse a las transacciones de mensuales de la entidad administradora de pagos de bajo valor. La información contiene detalle de los grupos, canales, tipos de transacciones, montos transados y todo lo detallado con cada transacción</p>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3. Problema comercial </h2>\n",
    "<p> En la empress SPVB se generan miles de registros transacciones a diario, se pretende dar respuesta con la data del modelo a diferentes necesidades las cuales son: </p>\n",
    "\n",
    "<li> 1. Crear un modelo para identificar y predecir las transaccio exitosas y con error</li>\n",
    "<li> 2. Modelo para inferir el tipo de transacción que pueden realizar los usuarios de la red.</li>\n",
    "<li> 3. Modelo de regresión lineal para predecir los retiros en efectivo y de esta manera provicionar el cash necesario para cubrir las necesidades de los usuarios.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. Data Acquisition </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/chech/PC Febrero 2023/1. Data Scients/CoderHouse/Data Scients/FinalProject/data/12. Dic22.csv')\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El tamaño del dataset es de: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5. Data Wrangling </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Data \n",
    "total = df.isnull().sum().sort_values(ascending = False)\n",
    "percent = (df.isnull().sum()/ df.isnull().count().sort_values(ascending = False)*100)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['total','percent'])\n",
    "missing_data.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Se reduce en Data Frame, eliminando las columnas con más del 78% de datos faltantes, algunas que son redundantes pues brindan la misma información en los modelos y alfunos features que a consideración no generan valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[['ID. Transaccion','Nombre Transaccion','BIN','ID. Canal','Nombre Canal','Error','Nombre Error',\n",
    "           'Responsable Error','ID. Origen','Nombre Origen','ID. Grupo','Nombre Grupo','Valor','Fecha Transaccion','Codigo Entidad Orgien',\n",
    "           'Cooperativa Terminal','ID. Terminal','Nombre Terminal','Serial Terminal','Tipo Documento',\n",
    "           'Documento','Departamento','Ciudad']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Convertir el cambo fecha en dd-mm-aaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Fecha Transaccion' al formato datetime\n",
    "df_1['Fecha Transaccion'] = pd.to_datetime(df_1['Fecha Transaccion'])\n",
    "\n",
    "# Extraer el día, mes y año y crear una nueva columna 'Fecha Formateada'\n",
    "df_1['Fecha Transaccion'] = df_1['Fecha Transaccion'].dt.strftime('%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas con valores no finitos en la columna \"Documento\"\n",
    "df_1 = df_1.dropna(subset=['Documento'])\n",
    "\n",
    "# Convertir los valores en la columna \"Documento\" de tipo float64 a int64\n",
    "df_1[\"Documento\"] = df_1[\"Documento\"].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Las transacciones de consulta, registrar valor 0 (cero) en la columna \"Valor\", con el fin de no mostrar movimientos financieros en transacciones de consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.loc[df_1['Nombre Transaccion'].str.contains('Consul'), 'Valor'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> En la columna valor, poner \"0\" (cero) a las transacciones que no fueron exitosas, esto con el fin de garantizar que no se sumen en la red valores que realmento no transaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar los valores de la columna \"Valor\" según la condición\n",
    "df_1.loc[df_1['Nombre Error'] != 'Exito', 'Valor'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos en 'Departamento' y 'Ciudad'\n",
    "df_1.dropna(subset=['Departamento', 'Ciudad'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna \"Departamento\" a tipo de dato entero\n",
    "df_1['Departamento'] = df_1['Departamento'].astype(int)\n",
    "\n",
    "# Convertir la columna \"Ciudad\" a tipo de dato entero\n",
    "df_1['Ciudad'] = df_1['Ciudad'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6. Feature Engineering </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 6.1 Función para asignar valores en función de la columna \"Error\" y crear una nueva columna binaria que indique \"1\" si la transaccion fue exitosa o \"0\" si fue error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignar_exito(row):\n",
    "    if row[\"Error\"] == 0 or row[\"Error\"] == 900:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df_1[\"Exito1-0\"] = df_1.apply(asignar_exito, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 6.2 Con el fin de categorizar las transacciones por rango del valor transado, se crea una nueva columna que indica en que rango esta cada transacción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rangos(valor):\n",
    "    if valor > 100000000:\n",
    "        return '+ 100 m'\n",
    "    elif valor > 50000000 and valor <= 100000000:\n",
    "        return '50 m-100 m'\n",
    "    elif valor > 20000000 and valor <= 50000000:\n",
    "        return '20 m-50 m'\n",
    "    elif valor > 5000000 and valor <= 20000000:\n",
    "        return '5 m-20 m'\n",
    "    elif valor > 1000000 and valor <= 5000000:\n",
    "        return '1 m-5 m'\n",
    "    elif valor > 200000 and valor <= 1000000:\n",
    "        return '200-1 m'\n",
    "    elif valor > 50000 and valor <= 200000:\n",
    "        return '50-200'\n",
    "    elif valor > 10000 and valor <= 50000:\n",
    "        return '10-50'\n",
    "    elif valor > 1 and valor <= 10000:\n",
    "        return '1-10'\n",
    "    else:\n",
    "        return 'Cero'\n",
    "df_1['NombreRango'] = df_1['Valor'].apply(rangos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 7. Exploratory Data Analysis - EDA </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 7.1 Visualización de valores null en el data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_1.isnull()\n",
    "    .melt().pipe(\n",
    "        lambda i:(\n",
    "            sns.displot(\n",
    "                data = i,\n",
    "                y = 'variable',\n",
    "                hue = 'value',\n",
    "                multiple = 'fill',\n",
    "                aspect = 2\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 7.2 Porcentaje de trasacciones exitosas Vs Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma_valores = df_1[\"Exito1-0\"].value_counts()\n",
    "\n",
    "# Crear la gráfica de torta\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(suma_valores, labels=[\"Exito\", \"Error\"], autopct='%1.1f%%', colors=['silver', 'red'], startangle=140)\n",
    "\n",
    "plt.title(\"Estado de las transacciones \")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 7.3 Cantidad de transacciones por rango. Lo cual nos da una idea muy acertada del comportamiento de las transacciones en terminos del valor $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteo_rangos = df_1['NombreRango'].value_counts()\n",
    "\n",
    "# Crear la gráfica de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(conteo_rangos.index, conteo_rangos.values, color='orange')\n",
    "\n",
    "# Personalizar la gráfica\n",
    "plt.title('Distribución de Transacciones por Rango')\n",
    "plt.xlabel('Rango')\n",
    "plt.ylabel('Conteo')\n",
    "\n",
    "# Rotar las etiquetas del eje x si es necesario\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 7.4 Cantidad de transacciones por canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar la columna 'Nombre Transaccion'\n",
    "nombre_transaccion = df_1['Nombre Canal']\n",
    "\n",
    "# Contar las ocurrencias de cada valor\n",
    "conteo_transacciones = nombre_transaccion.value_counts()\n",
    "\n",
    "# Crear la gráfica de barras horizontales\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=conteo_transacciones.values, y=conteo_transacciones.index, color='blue')\n",
    "\n",
    "# Personalizar la gráfica\n",
    "plt.title('Distribución de la columna \"Nombre Transaccion\"')\n",
    "plt.xlabel('Conteo')\n",
    "plt.ylabel('Nombre Transaccion')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 7.5 Cantidad de transacciones por cada tipo de transacción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_transaccion = df_1['Nombre Transaccion']\n",
    "\n",
    "# Contar las ocurrencias de cada valor\n",
    "conteo_transacciones = nombre_transaccion.value_counts()\n",
    "\n",
    "# Crear la gráfica de barras horizontales\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=conteo_transacciones.values, y=conteo_transacciones.index, color='green')\n",
    "\n",
    "# Personalizar la gráfica\n",
    "plt.title('Distribución de la columna \"Nombre Transaccion\"')\n",
    "plt.xlabel('Conteo')\n",
    "plt.ylabel('Nombre Transaccion')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature engineering - Segunda parte </h2>\n",
    "<p> Antes de iniciar con el proceso de modelado, procedemos a continuar haciendo feature engineering, con el fin de tener el dataset lo mejor posible para obtener un buen modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1[['ID. Origen','ID. Canal','ID. Transaccion','BIN','Valor','Codigo Entidad Orgien',\n",
    "             'Departamento', 'Ciudad', 'Error','Exito1-0', 'NombreRango','Tipo Documento','Documento']]\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Label Encoding </h4>\n",
    "<p> Transformar variables categóricas en variables numéricas. Consiste en asignar un número único a cada categoría en la columna categórica, convirtiendo así las etiquetas en valores enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Columnas para aplicar Label Encoding\n",
    "columns_to_encode = ['ID. Grupo', 'ID. Transaccion', 'BIN', 'NombreRango', 'Tipo Documento']\n",
    "\n",
    "# Crear un objeto LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Aplicar Label Encoding a cada columna\n",
    "for col in columns_to_encode:\n",
    "    if col in df_2.columns:\n",
    "        df_2[col] = label_encoder.fit_transform(df_2[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas numéricas\n",
    "columns_numeric = ['ID. Origen', 'ID. Canal', 'ID. Transaccion', 'BIN',\n",
    "                   'Valor', 'Codigo Entidad Orgien', 'Departamento', 'Ciudad', 'Error',\n",
    "                   'Exito1-0', 'NombreRango', 'Tipo Documento', 'Documento']\n",
    "\n",
    "# Crear un DataFrame con las columnas numéricas\n",
    "df_numeric = df_2[columns_numeric]\n",
    "\n",
    "# Calcular la matriz de correlaciones\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Crear la visualización de la matriz de correlaciones\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Matriz de Correlaciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 8. Seleccion de algoritmos apropiados </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 8.1 Crear un modelo para identificar y predecir las transaccio exitosas y con error </p>\n",
    "<h3> Regresión logistica y Random forest </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 8.2 Modelo para inferir el tipo de transacción que pueden realizar los usuarios de la red.</p>\n",
    "<h3> Random Forest</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 8.3 Modelo para predecir los retiros en efectivo y de esta manera provicionar el cash necesario para cubrir las necesidades de los usuarios.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 9. Desarrollo del algoritmo </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 8.1 Crear un modelo para identificar y predecir las transaccio exitosas y con error </p>\n",
    "<h2> Regresión Logística: </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hacer una copia del DataFrame df_2 y llamarla df_3\n",
    "df_3 = df_2.copy()\n",
    "\n",
    "# Sacar \"Exito1-0\" como target y las características\n",
    "X = df_3.drop('Exito1-0', axis=1)\n",
    "y = df_3['Exito1-0']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los features usando StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear y entrenar el modelo de Regresión Logística\n",
    "# Aumentamos el número máximo de iteraciones\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Definir los parámetros a probar para la optimización (en este caso solo C, el hiperparámetro de regularización)\n",
    "param_grid = {'C': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Usar validación cruzada (5-fold) para encontrar el mejor parámetro\n",
    "grid_search = GridSearchCV(logistic_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Obtener el mejor parámetro y su desempeño\n",
    "best_param = grid_search.best_params_\n",
    "print('Mejor parámetro para C:', best_param)\n",
    "\n",
    "# Entrenar el modelo con el mejor parámetro encontrado\n",
    "best_logistic_model = LogisticRegression(C=best_param['C'], max_iter=1000)\n",
    "best_logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_logistic = best_logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la exactitud del modelo\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print('Exactitud del modelo de Regresión Logística:', accuracy_logistic.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 8.2 Modelo para inferir el tipo de transacción que pueden realizar los usuarios de la red.</p>\n",
    "<h2> Random Forest </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[['Nombre Transaccion', 'ID. Transaccion']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2[['ID. Transaccion']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Features (X) y target (y)\n",
    "X = df_2.drop('ID. Transaccion', axis=1)  # Excluir la columna de 'ID. Transaccion'\n",
    "y = df_2['ID. Transaccion']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Random Forest\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "# Calcular la exactitud del modelo\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print('Exactitud del modelo de Random Forest:', accuracy_rf)\n",
    "\n",
    "# Mostrar el reporte de clasificación\n",
    "print('Reporte de clasificación:\\n', classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> 8.3 Modelo para predecir los retiros en efectivo y de esta manera provicionar el cash necesario para cubrir las necesidades de los usuarios </p>\n",
    "<h3> Regresión Lineal - Arboles de decision</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear df_4 con las filas de df_2 donde 'ID. Transaccion' está en la lista [3, 4, 14, 19]\n",
    "transacciones_filtradas = [3, 4, 14, 19]\n",
    "df_4 = df_2[df_2['ID. Transaccion'].isin(transacciones_filtradas)].copy()\n",
    "\n",
    "df_4 = df_4[(df_4['Codigo Entidad Orgien'].astype(str).str.len() <= 3) & (df_4['Codigo Entidad Orgien'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = df_4['Valor']\n",
    "\n",
    "# Crear la gráfica de caja de bigotes\n",
    "plt.boxplot(valores)\n",
    "plt.xlabel('Columna Valor')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Gráfico de Caja de Bigotes para la Columna Valor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Features (X) y target (y)\n",
    "X = df_4.drop('Valor', axis=1)  # Excluir la columna de 'Valor'\n",
    "y = df_4['Valor']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Regresión Lineal\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas de regresión (en este caso usamos r2_score y mean_squared_error)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('Coeficiente de determinación (R2):', r2)\n",
    "print('Error cuadrático medio (MSE):', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Features (X) y target (y)\n",
    "X = df_4.drop('Valor', axis=1)  # Excluir la columna de 'Valor'\n",
    "y = df_4['Valor']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Regresión de Árbol de Decisiones\n",
    "decision_tree_model = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = decision_tree_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas de regresión (en este caso usamos r2_score y mean_squared_error)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('Coeficiente de determinación (R2):', r2)\n",
    "print('Error cuadrático medio (MSE):', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10. Conclusiones </h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyectoCoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
